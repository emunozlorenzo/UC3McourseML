{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBFy3UxPIyjH"
   },
   "source": [
    "# Embeddings\n",
    "\n",
    "### Curso Intermedio de Aprendizaje Automático 2021\n",
    "\n",
    "**Vanessa Gómez Verdejo, Emilio Parrado Hernández,  Pablo Martínez Olmos**\n",
    "\n",
    "Departamento de Teoría de la Señal y Comunicaciones\n",
    "\n",
    "**Universidad Carlos III de Madrid**\n",
    "\n",
    "<img src='http://www.tsc.uc3m.es/~emipar/BBVA/INTRO/img/logo_uc3m_foot.jpg' width=400 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACDSB7Y5WmYN"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "# Figures plotted inside the notebook\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# High quality figures\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3W238BoIyg3"
   },
   "source": [
    "# Introducción\n",
    "\n",
    "Un *embedding* es una representación vectorial de nuestros datos en un espacio de dimensión relativamente bajo. La representación mediante *embeddings* suele utilizarse para facilitar el aprendizaje de modelos cuando se tienen que manejar datos categóricos o conceptos cuya codificación suele llevar a representaciones *sparse* de alta dimensión, como pueden ser codificaciones one-hot encoding de variables categóricas estandar,  representaciones BoW o TF-IDF de documentos o los *ratings* con que un usuario ha puntuado a un conjunto de películas  en un sistema de recomendación. \n",
    "\n",
    "Así, por ejemplo, una codificación one-hot de paises y ciudades nos llevaría a vectores de este tipo:\n",
    "\n",
    "<img src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/BBVA/Embeddings/OneHotEncoding.png\" width=\"40%\"> \n",
    "\n",
    "\n",
    "Al utilizar este tipo de representaciones en un sistema de aprendizaje automático nos encontramos varias limitaciones:\n",
    "* Por un lado, trabajar con un espacio de muy alta dimensión implica entrenar un modelo con muchos parámetros, lo que a su vez conlleva un mayor coste computacional, riesgo de sobreajuste, ...\n",
    "* Por otro lado, el tener que manjear representaciones dispersas dificulta el cálculo de distancias entre elementos así como la identificación de elementos similares. Por ejemplo, la codificación anterior nos va a dar la misma distancia entre Rome y Paris que entre Rome e Italia.\n",
    "\n",
    "Por tanto, para utilizar este tipo de representaciones en un sistema de aprendizaje automático, necesitamos una forma de representar cada vector disperso como un vector de números para el que los elementos semánticamente similares (ciudades, películas o palabras) tengan distancias similares en el espacio vectorial. La solución a estos problemas es utilizar *embeddings*, ya que son capaces de transformar grandes vectores dispersos a un espacio de menor dimensión que preserva las relaciones semánticas. \n",
    "\n",
    "Idealmente, un buen *embedding* debe proporcionar un conjunto de vectores cuya posición (distancia y dirección) en el espacio vectorial codifique la semántica de los datos que representan. Las siguientes visualizaciones$^{(*)}$ de *embeddings* reales muestran relaciones geométricas que capturan relaciones semánticas como el genero, un tiempo verbal o la relación entre un país y su capital\n",
    "\n",
    "<img src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/BBVA/Embeddings/Embeddings1.svg\" width=\"80%\"> \n",
    "\n",
    "Además, la representación de los datos mediante  *embeddings* tiene varias ventajas:\n",
    "* Ayuda al aprendizaje del modelo, ya que reducirá el coste computacional y evitará problemas de sobreajuste. Ademáás, si el *embedding* está bien diseñado, proporcionará una representación más informativa de los datos que facilitará aprender las relaciones subyacentes entre estos datos. \n",
    "* Esta representación puede aprenderse y reutilizarse en distintos modelos.\n",
    "* Al manejar los datos en un espacio de menor dimensión se facilita su representación, ya sea porque el *embedding* nos permite tener los datos en un espacio de dos o tres dimensiones o porque se puede combinar con algoritmos de visualización (que veremos más adelante) que nos permiten visualizar lo que está ocurriendo en este espacio del *embedding*.\n",
    "\n",
    "$^{(*)}$ https://developers.google.com/machine-learning/crash-course/embeddings/translating-to-a-lower-dimensional-space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEX0Zp4mIycQ"
   },
   "source": [
    "## ¿Cómo podemos obtener estos *embeddings*? \n",
    "\n",
    "Dado que los *embeddings* no son más que una representación de los datos en un espacio de menor dimensión, podemos utilizar **técnicas estándar de reducción de la dimensionalidad** para su cálculo. En este sentido, existen muchas técnicas matemáticas para capturar la estructura de un espacio de alta dimensión en un espacio de baja dimensión. En teoría, cualquiera de estas técnicas podría utilizarse para crear un *embedding* para un sistema de aprendizaje automático:\n",
    "* El análisis de componentes principales (PCA) se ha utilizado para crear *embeddings* de palabras. Así, por ejemplo, dado un conjunto de datos representado por un BoW, el PCA nos permite encontrar dimensiones altamente correlacionadas que puedan ser proyectadas en una sola dimensión.\n",
    "* Los métodos de agrupamiento como el K-means o el GMM (Gaussian Mixture Model) nos permiten obtener una representación alternativa de los datos mediante la distancia de cada dato a los centroides o, en el caso del GMM, mediante la probabilidad de pertencia de cada dato a cada elemento de la mezcla. De este modo, cada dato podría representarse en un nuevo espacio cuya dimensión viene dada por el número de centroides.\n",
    "\n",
    "También puede aprender un *embedding* como parte de una **red neuronal profunda (DNN, Deep Neural Network)**. Este enfoque permite obtener *embeddings* adaptados a tareas concretas que intentan conservar la semántica de los datos. En general, cuando se tienen datos dispersos (o incluso datos densos para los que se desea obtener un *embedding*), se puede entrenar una red neuronal donde la capa final resuelve nuestra tarea objetivo, pero donde se incluye una capa específica para obtener esta representación. Así, por ejemplo, para un sistema de recomendación podemos diseñar una red de este tipo $^{(**)}$:\n",
    "\n",
    "\n",
    "<img src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/BBVA/Embeddings/Embeddings2.svg\" width=\"80%\"> \n",
    "\n",
    "\n",
    "Esta aproximación para construir *embeddings* fue propuesta por Google para obtener representaciones vectoriales o *embeddings* para palabras en lo que se conoce como *Word2vec* donde el diseño de la red se hace de modo que palabras semánticamente similares se proyecten en *embeddings* geométricamente cercanos. Más adelante, esta aproximación se extendió a su uso en sistemas de recomendación para la codificación de productos o items mediante lo que se conoce como *Prod2Vec*.\n",
    "\n",
    "\n",
    "A lo largo de este notebook aprenderemos cómo utilizar estos métodos para obtener  *embeddings* en diferentes aplicaciones y cómo se utilizan las diferentes herramientas que hay para su cálculo.\n",
    "\n",
    "$^{(**)}$ https://developers.google.com/machine-learning/crash-course/embeddings/obtaining-embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByhKSdYmRjgX"
   },
   "source": [
    "# PCA para la obtención de *embeddings* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADt3yG_fRjdl"
   },
   "source": [
    "## Review: Análisis de Componentes Principales\n",
    "\n",
    "<img align=\"right\" src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/PCA/PCA_1.png\" width=\"40%\" >\n",
    "\n",
    "El objetivo del PCA es encontrar una nueva representación de los datos, sobre un espacio de baja dimensión ($K<D$), de forma que se consiga maximizar la varianza de los datos proyectados. Esta nueva representación de los datos, que serán nuestros **embeddings**, viene dada por una transfomación lineal de los mismos:\n",
    "\n",
    "$${\\bf X'} = {\\bf U}^T {\\bf X}^T$$\n",
    "\n",
    "Por lo que el objetivo del PCA será encontrar esta matriz de transfomación ${\\bf U}$, para a continuación obtener la nueva representación o *embedding* de los datos. Cada columna de esta matriz, llamada **componente principal**, proporcionará una nueva dimensión de los datos en el espacio proyectado.\n",
    "\n",
    "Para obtener esta representación directamente podemos utilizar la implementación de [sklearn del PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8f_M__mcmB0"
   },
   "source": [
    "## Embeddings para la clasificación de dígitos\n",
    "\n",
    "Para aplicar este modelo y ver la utilidad de los *embeddings*  vamos a utilizar como aplicación la clasificación de digitos manuscritos, así que empecemos cargando nuestro dataset.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ViHbU3FOWcxT"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits(n_class=6) # For this example we only use 6 digits (0-5)\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsLcpdJva6Gu"
   },
   "source": [
    "cada uno de los datos se corresponde con una imágen de un dígito manuscrito..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OgpaJMVobKXK"
   },
   "outputs": [],
   "source": [
    "def plot_digit(images, titles, h, w, n_row=4, n_col=10):\n",
    "    \"\"\"Helper function to plot digits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.colorbar()\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        \n",
    "# As example, we plot a number of each class (or person)\n",
    "titles = ['class '+str(c) for c in range(6)]\n",
    "ind_digit = [np.where(y == c)[0][0] for c in range(6)]\n",
    "\n",
    "plot_digit(X[ind_digit,:], titles, h=8, w=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naNsb-uXak5z"
   },
   "source": [
    "Aquí cada dígito viene representado con una imagen de $8x8$ píxeles que se representa con un vector disperso que no hace más que asignar un valor de intensidad (entre $0$ y $16$) a cada uno de los píxeles de la imagen.  La base de datos original de MNIST se compone de imágenes de $32x32$ con valores de intensidad a $1$ o $0$, esta base de datos se ha generado tomando los cuadrados $4x4$ y sumando las intensidades de cada cuadrado, por eso estos píxeles tiene valores de intensidad entre 0 y 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7p2wk6g-WeAw"
   },
   "outputs": [],
   "source": [
    "X[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-YaLcBqc85B"
   },
   "source": [
    "Como hemos indicado, podemos obtener una representación alternativa (*embedding*) de estas imágenes aplicando un PCA..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iv2FArnudbix"
   },
   "source": [
    "### Ejercicio\n",
    "Complete la siguiente celda para obtener un *embedding* de dimensión 64 mediante un PCA  para el problema anterior (más adelante reduciremos la dimensión de este *embedding*).\n",
    "\n",
    "Una vez obtenido el *embedding*, guardelo en la variable `X_pca` para que la siguiente celda de código le permita analizar diferentes aspectos de esta transformación, así como visualizar las dos primeras componentes de este *embedding*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvAkbzKjdQiQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "N_feat_max=64\n",
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyC-Cv_adpJG"
   },
   "source": [
    "### Análisis del tamaño embedding con PCA\n",
    "Vamos a analizar los autovalores del PCA así como la varianza acumulada en los datos transformados en función del tamaño del *embedding*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EalbHLINdt4r"
   },
   "outputs": [],
   "source": [
    "# 1. Analyze eigenvalues\n",
    "eigenvalues = my_pca.explained_variance_\n",
    "plt.figure()\n",
    "plt.plot(eigenvalues, label='Evolution eigenvalues')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 2.- Compute an estimation of the variance in data using the training set\n",
    "\n",
    "data_variance = np.sum(np.var(X,0))\n",
    "\n",
    "# 3.- plot the explain variance of each eigenvector and cummulative sum of the sorted eigenvalues divided by the total variance of the data\n",
    "# 3.1.- express the y-axis in percentage\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(100*eigenvalues/data_variance, label='Explained variance by eigenvector')\n",
    "plt.grid()\n",
    "plt.xlabel('$K$: Number of principal components')\n",
    "plt.ylabel('Percentage of the variance')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(100*np.cumsum(eigenvalues)/data_variance, label='Cumulative explained variance')\n",
    "plt.grid()\n",
    "plt.xlabel('$K$: Number of principal components')\n",
    "plt.ylabel('Percentage of the variance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xj6c0cYxOblQ"
   },
   "source": [
    "A la vista de esta figura, ¿cuántos componentes principales crees que son suficientes para obtener un buen embedding de los datos y no perder información relevante?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_CJDU7xuomK"
   },
   "source": [
    "### Visualización del embedding \n",
    "\n",
    "Además, el embedding también nos sirve para visualizar la distribución de los datos. En este caso, como las primeras componentes del PCA tienen la mayor parte de la información (varianza) podemos usar las dos primeras componentes del PCA para ver lo que ocurre en el espacio del *embedding*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jP93thUeEpl"
   },
   "outputs": [],
   "source": [
    "from matplotlib import offsetbox\n",
    "\n",
    "# Scale and visualize the embedding vectors\n",
    "def plot_embedding(X,y, digits):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "  \n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(X[i, 0], X[i, 1], str(y[i]),\n",
    "                 color=plt.cm.Set1((y[i]+1 )/ 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "    # Add some example images\n",
    "    if hasattr(offsetbox, 'AnnotationBbox'):\n",
    "        # only print thumbnails with matplotlib > 1.0\n",
    "        shown_images = np.array([[1., 1.]])  # just something big\n",
    "        for i in range(X.shape[0]):\n",
    "            dist = np.sum((X[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < 4e-3:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.r_[shown_images, [X[i]]]\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r),\n",
    "                X[i])\n",
    "            ax.add_artist(imagebox)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "   \n",
    "\n",
    "# Plot two first PCA dimensions\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_embedding(X_pca[:,:2],y, digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bz4cbOx8f4nN"
   },
   "source": [
    "### Diseño del embedding para la clasificación de dígitos \n",
    "Podemos diseñar un pipeline (incluyendo una posterior etapa de clasificación con un K-NN) para seleccionar el tamaño adecuado de nuestro embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWoSdXVEiXpj"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Split into a training and testing set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.6)\n",
    "\n",
    "# Define pipeline steps\n",
    "pipe = Pipeline([('PCA', PCA()),\n",
    "                 ('kNN', neighbors.KNeighborsClassifier( ))])\n",
    "\n",
    "# Define parameters to CV\n",
    "param_grid = {\n",
    "    'PCA__n_components': np.arange(1,20),\n",
    "    'kNN__n_neighbors': np.arange(1,5),\n",
    "    'kNN__weights':['uniform','distance'],\n",
    "}\n",
    "\n",
    "# CV with GridSearchCV\n",
    "grid_pipe = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid_pipe.fit(X_train, Y_train)\n",
    "\n",
    "# Test\n",
    "accuracy_train_knn = grid_pipe.score(X_train,Y_train)\n",
    "accuracy_test_knn = grid_pipe.score(X_test,Y_test)\n",
    "\n",
    "print(\"El número de componentes de PCA es {0:d}\".format(grid_pipe.best_estimator_['PCA'].n_components))\n",
    "print(\"El número de vecinos seleccionado es k={0:d}\".format(grid_pipe.best_estimator_['kNN'].n_neighbors))\n",
    "print(\"Accuracy train {0:.2f}%. Accuracy test {1:.2f}%\\n\".format(accuracy_train_knn*100, accuracy_test_knn*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WOOwY7aW15O"
   },
   "source": [
    "# K-means y GMM para la obtención de *embeddings* \n",
    "\n",
    "Los algoritmos de agrupamiento o *clustering* también nos sirven para hacer una reducción de dimensionalidad. Para entender cómo funcionan y cómo podemos extraer una representación de baja dimensión de nuestros datos a partir de ellos, empecemos considernado el algoritmo K-means, haciendo una pequeña revisión del mismo (aunque ya lo hemos visto en el curso de *Fundamentals of ML*) y viendo cómo nos pueden ayudar para reducir la dimensión de nuestros datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TB2yiZucXnAH"
   },
   "source": [
    "## Review: K-means\n",
    "\n",
    "\n",
    "El algoritmo k-means es un algoritmo particularmente sencillo que nos permite encontrar grupos (clusters) sobre un conjunto de datos de forma **no supervisada**. Estos grupos pueden ser útiles para entender la estructura de nuestros datos y, por tanto, nos pueden ayudar a obtener una representación alternativa de los mismos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnmO7mMkYAw7"
   },
   "source": [
    "\n",
    "Dado un dataset, una **distancia** entre cualquier par de puntos y un número $K$ prefijado de grupos, K-means implementa el siguiente algoritmo iterativo para asignar cada dato a una de los $K$ posibles grupos:\n",
    "\n",
    "* **Inicialización**. Cada grupo se caracteriza por un *centroide* que se inicializa, por ejemplo, escogiendo aleatoriamente un punto de nuestro dataset. \n",
    "\n",
    "* **Iterativavemente**, hasta la convergencia se repiten los siguientes pasos:\n",
    "\n",
    "  - **Paso I: asignación**. Cada dato del dataset se asigna al grupo cuyo centroide esté más cerca de acuerdo a la métrica de distancia. \n",
    "  - **Paso II: actualizar centroides**. Dadas las asignaciones de los datos a los grupos, se recalculan los centroides como la media aritmética de los puntos asignados a cada grupo.\n",
    "\n",
    "  Si no hay cambios en la asignación de puntos a grupos entre dos iteraciones consecutivas, el algoritmo ha convergido. En caso contrario seguimos iterando.\n",
    "\n",
    "\n",
    "<img src='http://www.tsc.uc3m.es/~olmos/BBVA/k-mean_good.jpg' width=1000 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeU1kH_NYYRH"
   },
   "source": [
    "**Aspectos a tener en cuenta:**\n",
    "\n",
    "* Es un algoritmo muy sensible a la inicialización. En la práctica, el algoritmo k-means es muy rápido (uno de los algoritmos de agrupamiento más rápidos disponibles), pero su solución no es única (hay muchos mínimos locales). Por eso puede ser útil reiniciarlo varias veces y quedarnos la solución que obtiene los grupos más compactos.\n",
    "* El número de vecinos $K$ es un parámetro del modelo que debemos ajustar. Aunque normalmente no podemos utilizar esquemas de CV al estar en un escenario no supervisado, para el diseño de *embeddings* en los que hay una etapa posterior de clasificación, podemos usar el error del clasificador para elegir este parámetro.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWnrdW1mQ5qm"
   },
   "source": [
    "## Obtención de embeddings con K-means\n",
    "\n",
    "Para ver cómo podemos obtener una representación de baja dimensión o *embedding* a partir de un algoritmo de agrupamiento, consideraremos un ejemplo similar al de la figura anterior para poder visualizar el resultado fácilmente ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Im-TuzVDTBEF"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "rng = np.random.RandomState(36)\n",
    "\n",
    "X_blob, y_true = make_blobs(n_samples=500, centers=6,\n",
    "                       cluster_std=0.6, random_state=22)\n",
    "\n",
    "\n",
    "# K-means con K=4\n",
    "K=4\n",
    "\n",
    "kmeans = KMeans(n_clusters=K) # Definimos objeto con parámetros por defecto\n",
    "kmeans.fit(X_blob) # Entrenamos k-means\n",
    "y_kmeans = kmeans.predict(X_blob) # Obtenemos el identificador del grupo para cada dato\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Plot k-means result\n",
    "plt.scatter(X_blob[:, 0], X_blob[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=500, alpha=0.5)\n",
    "\n",
    "plt.grid(b=True, which='major', color='gray', alpha=0.6, linestyle='dotted', lw=1.5)\n",
    "\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrlpUiSNT5M2"
   },
   "source": [
    "Una vez tenemos definidos grupos y centroides asociados a estos grupos, una opción para representar nuestros datos sería considerar la pertenencia de cada dato a un grupo como representación. De este modo, los datos del primer grupo podrían codificarse como [1,0,0,0], los datos del segundo grupo como [0,1,0,0] y así sucesivamente. Pero esto nos llevaría a una representación dispersa de los datos que, como sabemos, no es lo más deseable.\n",
    "\n",
    "Para evitar esto, podemos representar cada dato con la distancia a los diferentes centroides. De este modo, para este ejemplo, tendríamos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQYyFzKWTBBf"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "# Embeddings are distances to centers\n",
    "X_embed = pairwise_distances(X_blob, centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlZlHV8iU9Ng"
   },
   "source": [
    "Con esto hemos cambiado la representación de nuestros datos y ahora tienen tantas componentes como centroides (en este caso particular hemos pasado de un problema de 2 dimensiones a un problema de 4), pero esta nueva representación es más discriminativa entre grupos de datos, es decir, captura la estructura del agrupamiento entre los datos... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FpjQf-ZyTA-7"
   },
   "outputs": [],
   "source": [
    "# Embedding of group 0\n",
    "print('Algunos ejemplos del embedding para el grupo 0')\n",
    "ind = np.where(y_true == 0)[0][:10] \n",
    "print(X_embed[ind,:])\n",
    "# Embedding of group 1\n",
    "print('Algunos ejemplos del embedding para el grupo 1')\n",
    "ind = np.where(y_true == 1)[0][:10] \n",
    "print(X_embed[ind,:])\n",
    "# Embedding of group 2\n",
    "print('Algunos ejemplos del embedding para el grupo 2')\n",
    "ind = np.where(y_true == 2)[0][:10] \n",
    "print(X_embed[ind,:])\n",
    "# Embedding of group 3\n",
    "print('Algunos ejemplos del embedding para el grupo 3')\n",
    "ind = np.where(y_true == 3)[0][:10] \n",
    "print(X_embed[ind,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qc9vZIHHVwb4"
   },
   "source": [
    "Veamos ahora cómo aplicar esta transformación al problema de clasificación de dígitos anterior, donde de verdad veremos cómo esta aproximación nos da una reducción de dimensionalidad... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znrjlcVmV7cy"
   },
   "source": [
    "### Ejercicio\n",
    "Complete la siguiente celda de código para obtener un *embedding* de dimensión 2 mediante un K-means para el problema de clasificación de digitos. De momento, trabaje con todo el conjunto original almacenado en la variable `X`.\n",
    "\n",
    "Una vez obtenido el *embedding*, guardelo en la variable `X_kmeans` para que la siguiente celda de código le permita visualizarlo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uvou2YWhBMSP"
   },
   "outputs": [],
   "source": [
    "K=2\n",
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYgb92oIBMKn"
   },
   "outputs": [],
   "source": [
    "# Plot Kmeans embedding\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_embedding(X_kmeans, y, digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bz_twuzcEWao"
   },
   "source": [
    "Este tipo de representación suele llevar a espacios con más dimensiones que el PCA, pero funcionan muy bien cuando nuestros datos están realmente distribuidos en grupos definidos de datos ya que son capaces de capturar muy bien esta estructura. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRjgeqXeg2cE"
   },
   "source": [
    "### Análisis del tamaño del embedding con K-means\n",
    "\n",
    "Veamos con el siguiente ejemplo cual sería la dimensión adecuada de nuestro *embedding* para obtener buenas prestaciones en una posterior clasificación con un K-NN. Nótese que, a diferencia del PCA, aquí no podemos usar un pipeline ya que el k-means y el cálculo de las distancias a los centroides no son transformaciones predefinidas de los métodos de sklearn, así que nos vamos a conformar con ir barriendo el tamaño del embedding (número de centroides) y analizar las prestaciones en test sobre este parámetro..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0X3UizskMSi_"
   },
   "outputs": [],
   "source": [
    "# Define parameters to CV\n",
    "param_grid = {\n",
    "    'n_neighbors': np.arange(1,10),\n",
    "    'weights':['uniform','distance'],\n",
    "}\n",
    "\n",
    "for K in range(2,21,2):\n",
    "  # train K-means for embedding computation\n",
    "  kmeans = KMeans(n_clusters=K) # Definimos objeto con parámetros por defecto\n",
    "  kmeans.fit(X_train) # Entrenamos k-means\n",
    "  # Get centers\n",
    "  centers = kmeans.cluster_centers_\n",
    "  \n",
    "  # Embeddings are distances to centers\n",
    "  X_kmeans_train = pairwise_distances(X_train, centers)\n",
    "  X_kmeans_test = pairwise_distances(X_test, centers)\n",
    "  \n",
    "  # CV with GridSearchCV\n",
    "  grid_knn = GridSearchCV(neighbors.KNeighborsClassifier( ), param_grid, cv=5)\n",
    "  grid_knn.fit(X_kmeans_train, Y_train)\n",
    "\n",
    "  # Test\n",
    "  accuracy_train_knn = grid_knn.score(X_kmeans_train,Y_train)\n",
    "  accuracy_test_knn = grid_knn.score(X_kmeans_test,Y_test)\n",
    "\n",
    "  print(\"El número de componentes del embedding es {0:d}\".format(K))\n",
    "  print(\"Accuracy train {0:.2f}%. Accuracy test {1:.2f}%\\n\".format(accuracy_train_knn*100, accuracy_test_knn*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqK9QBQAXpjs"
   },
   "source": [
    "## Review: Gaussian Mixture Model\n",
    "\n",
    "Un GMM permite modelar la distribución de nuestros datos como una mezcla de distribuciones gaussianas parametrizada del siguiente modo:\n",
    "\n",
    "\\begin{align}\n",
    "p(\\mathbf{x}) = \\sum_{k=1}^{K} \\pi_k \\mathcal{N}(\\mathbf{x}|\\mathbf{\\mu}_k,\\mathbf{\\Sigma}_k)\n",
    "\\end{align}\n",
    "\n",
    "donde $(\\pi_1,\\ldots,\\pi_K)$, $(\\boldsymbol{\\mu}_1,\\ldots,\\boldsymbol{\\mu}_K)$, $(\\mathbf{\\Sigma}_1,\\ldots,\\mathbf{\\Sigma}_K)$ son los **parámetros del modelo**, en concreto:\n",
    "\n",
    "- $\\pi_k$ es la probabilidad de que el dato provenga de la componente $k$-ésima de la mezcla.\n",
    "\n",
    "- $\\mathcal{N}(\\mathbf{x}|\\boldsymbol{\\mu}_k,\\mathbf{\\Sigma}_k)$ modela a cada una de las gaussianas que forman la mezcla. La gaussiana $k$-ésima tiene media $\\boldsymbol{\\mu}_k$ y matriz de covarianzas $\\mathbf{\\Sigma}_k$. \n",
    "\n",
    "\n",
    "Los parámetros del modelo se escogen para maximizar la **probabilidad de los datos ya observados o evidencia**:\n",
    "\n",
    "$$ \\max_{(\\pi_1,\\ldots,\\pi_K),(\\boldsymbol{\\mu}_1,\\ldots,\\boldsymbol{\\mu}_K), (\\mathbf{\\Sigma}_1,\\ldots,\\mathbf{\\Sigma}_K)}  ~~\\sum_{n=1}^{N} \\log  p(\\mathbf{x}_n) $$\n",
    "\n",
    "Este problema se resuelve de forma numérica mediante un algoritmo iterativo conocido como **EM** (Expectation-Maximization). Para implementarlo podemos usar la clase [GaussianMixture](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html) de sklearn.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmyFZz5YVD02"
   },
   "source": [
    "\n",
    "Usando GMMs, podemos solventar dos **limitaciones importantes** de K-means:\n",
    "\n",
    "- K-means asume de forma implícita que los **grupos son esféricos** (todos los puntos que están a la misma del centroide). El GMM nos deja modelar diferentes matrices de covarianza $\\mathbf{\\Sigma}_k$ para cada centroide y con ello los grupos pueden tener formas más diversas (elíptica, etc).\n",
    "\n",
    "- Mientras que el K-means hace una asignación **dura** de cada punto a un grupo, el GMM proporciona una medida de incertidumbre para identificar puntos que están cerca de varios grupos. De hecho, dado un dato $\\bf x$, podemos calcular la **probabilidad a posteriori** de que cada grupo haya generado dicho dato:\n",
    "$$P(\\text{cluster}=k|\\mathbf{x})= \\frac{\\pi_{k} \\mathcal{N}(\\mathbf{x}|\\boldsymbol{\\mu}_{k},\\mathbf{\\Sigma}_{k})}{\\sum_{q=1}^K \\pi_{q} \\mathcal{N}(\\mathbf{x}|\\boldsymbol{\\mu}_{q},\\mathbf{\\Sigma}_{q})}$$\n",
    "Esto significa que tenemos una **probabilidad de pertenecer a cada grupo**, en lugar de una asignación dura que es lo que proporcionaba K-means.\n",
    "En sklearn, podemos calcular dichas probabilidades usando el método `predict_proba`.\n",
    "\n",
    "Por último, al igual en el K-means, necesitamos seleccionar el número de grupos. Del mismo modo que en K-means, esto no es sencillo en tareas no supervisadas, pero para el diseño de *embeddings* en datasets etiquetados, podemos usar un clasificador para evaluar el mejor tamaño del *embedding*.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvqXcOvzX8WE"
   },
   "source": [
    "## Obtención de embeddings con GMM\n",
    "Si en el K-means usábamos la distancia de los datos a los centroides para obtener un *embedding*, en el GMM directamente podemos utilizar la probabilidad de pertenecia a cada grupo para obtener esta representación.\n",
    "Veamos cómo sería este *embedding* con el ejemplo de juguete, para ello empecemos representando los datos y la distribución de probabilidad que modela el GMM..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jL4mkLmEYOzj"
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import multivariate_normal as mvn #Multivariate normal distribution\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "# GMM con K=4\n",
    "K=4\n",
    "gmm = GaussianMixture(n_components=K,covariance_type='full',n_init=10) \n",
    "gmm.fit(X_blob) \n",
    "\n",
    "\n",
    "# Lets plot the pdf contour plot\n",
    "intervals = 200\n",
    "\n",
    "# Creamos una rejilla\n",
    "x_mesh = np.linspace(-12, 2, intervals)\n",
    "y_mesh = np.linspace(-6, 10, intervals)\n",
    "\n",
    "X_mesh,Y_mesh = np.meshgrid(x_mesh,y_mesh)\n",
    "\n",
    "xys = np.vstack([X_mesh.ravel(), Y_mesh.ravel()]).T\n",
    "\n",
    "\n",
    "Zgmm = np.zeros(len(xys))\n",
    "for k in range(K):\n",
    "    Zgmm += gmm.weights_[k]*mvn(gmm.means_[k,:], gmm.covariances_[k]).pdf(xys)\n",
    "    \n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "Zgmm = Zgmm.reshape([intervals,intervals])\n",
    "ax.contour(X_mesh, Y_mesh, Zgmm, 20, cmap=cm.coolwarm) \n",
    "ax.scatter(X_blob[:, 0], X_blob[:, 1], s=40, cmap='viridis')\n",
    "ax.grid(b=True, which='major', color='gray', alpha=0.6, linestyle='dotted', lw=1.5)\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "surf = ax.plot_surface(X_mesh, Y_mesh, Zgmm, cmap=cm.coolwarm)\n",
    "ax.grid(b=True, which='major', color='gray', alpha=0.6, linestyle='dotted', lw=1.5)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnGSChIGV2jl"
   },
   "source": [
    "Si ahora calculamos la probabilidad de pertenecia de los datos a los diferentes centroides o gaussianas, podemos obtener el *embedding* de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TItw2LgYfwf"
   },
   "outputs": [],
   "source": [
    "X_blobs_gmm = gmm.predict_proba(X_blob)\n",
    "\n",
    "# Embedding of group 0\n",
    "print('Algunos ejemplos del embedding para el grupo 0')\n",
    "ind = np.where(y_true == 0)[0][:10] \n",
    "print(X_blobs_gmm[ind,:])\n",
    "# Embedding of group 1\n",
    "print('Algunos ejemplos del embedding para el grupo 1')\n",
    "ind = np.where(y_true == 1)[0][:10] \n",
    "print(X_blobs_gmm[ind,:])\n",
    "# Embedding of group 2\n",
    "print('Algunos ejemplos del embedding para el grupo 2')\n",
    "ind = np.where(y_true == 2)[0][:10] \n",
    "print(X_blobs_gmm[ind,:])\n",
    "# Embedding of group 3\n",
    "print('Algunos ejemplos del embedding para el grupo 3')\n",
    "ind = np.where(y_true == 3)[0][:10] \n",
    "print(X_blobs_gmm[ind,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HltIiIpidggb"
   },
   "source": [
    "Como vemos en este caso, al tener datos claramente asignados a un grupo, su probabilidad de pertencia a cada grupo tiende a ser uno o cero, dando *embeddings* practicamente binarios (no hay datos entre dos grupos). Esto suele ocasionar que el número de grupos o el tamaño del *embedding* tienda a ser mayor que en las aproximaciones anteriores.\n",
    "\n",
    "Veamos cómo se comporta este *embedding* en el problema de clasificación de digitos...   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZuVkH8qRfxac"
   },
   "source": [
    "### Ejercicio\n",
    "Complete la siguiente celda de código para obtener un *embedding* de dimensión 2 usando un modelo GMM para el problema de clasificación de digitos. De momento, trabaje con todo el conjunto original almacenado en la variable `X`.\n",
    "\n",
    "Una vez obtenido el *embedding*, guárdelo en la variable `X_gmm` para que la siguiente celda de código le permita visualizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUv63s6s7pTi"
   },
   "outputs": [],
   "source": [
    "k=2 # For representative purposes\n",
    "#<SOL>\n",
    "#</SOL>\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UrKCKdfL_5vM"
   },
   "outputs": [],
   "source": [
    "# Plot GMM embedding\n",
    "plt.figure(figsize=(4,4))\n",
    "plot_embedding(X_gmm, y, digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8to-0T9mhXqC"
   },
   "outputs": [],
   "source": [
    "# Plot GMM embedding\n",
    "plt.figure(figsize=(8,8))\n",
    "# Let's represent again with some noise to uncolapse the data\n",
    "plot_embedding(X_gmm + 0.2*np.random.rand(X_gmm.shape[0],X_gmm.shape[1]), y, digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0l8I9Tei8hC"
   },
   "source": [
    "Como vemos y tal y como esperábamos, el embedding del GMM con solo dos dimensiones acaba proyectando muchos valores en un único punto. Esto hace que estas variables no vayan a ser de utilidad para clasificar, está claro que necesitamos aumentar la dimensión del embedding..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSs3kAq6RBEq"
   },
   "source": [
    "### Análisis del tamaño del embedding con GMM\n",
    "\n",
    "Al igual que con el K-means podemos analizar la influencia del tamaño del embedding en un posterior proceso de clasificación (con un K-NN). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHszhJQD7pRD"
   },
   "outputs": [],
   "source": [
    "# Define parameters to CV\n",
    "param_grid = {\n",
    "    'n_neighbors': np.arange(1,10),\n",
    "    'weights':['uniform','distance'],\n",
    "}\n",
    "\n",
    "for K in range(5,101,5):\n",
    "  # train GMM for embedding computation\n",
    "  gmm = GaussianMixture(n_components=K,covariance_type='full',n_init=10) \n",
    "  gmm.fit(X_train) \n",
    "\n",
    "  # Embeddings are probabilities of belonging to each center\n",
    "  X_gmm_train = gmm.predict_proba(X_train)\n",
    "  X_gmm_test = gmm.predict_proba(X_test)\n",
    " \n",
    "  # CV with GridSearchCV\n",
    "  grid_knn = GridSearchCV(neighbors.KNeighborsClassifier( ), param_grid, cv=5)\n",
    "  grid_knn.fit(X_gmm_train, Y_train)\n",
    "\n",
    "  # Test\n",
    "  accuracy_train_knn = grid_knn.score(X_gmm_train, Y_train)\n",
    "  accuracy_test_knn = grid_knn.score(X_gmm_test, Y_test)\n",
    "\n",
    "  print(\"El número de componentes del embedding es {0:d}\".format(K))\n",
    "  print(\"Accuracy train {0:.2f}%. Accuracy test {1:.2f}%\\n\".format(accuracy_train_knn*100, accuracy_test_knn*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOlAImnSj2LE"
   },
   "source": [
    "# Embeddings con redes neuronales: word2vec \n",
    "\n",
    "Word2vec es un algoritmo inventado en Google para diseñar *embeddings* de palabras. Word2vec se basa en la premisa de que palabras con significado similar deben ser codificadas con vectores geométricamente cercanos. Para ello se considera que las palabras que suelen tener las mismas palabras vecinas (contexto) tienden a ser semánticamente similares. Tanto \"perro\" como \"gato\" aparecen con frecuencia cerca de la palabra \"veterinario\", y este hecho refleja su similitud semántica. \n",
    "\n",
    "Hay diferentes esquemas para construir un word2vec, aquí vamos a ver el modelo más común que es el Skip-Gram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kPgrHHorAuN"
   },
   "source": [
    "## Modelo Skip-Gram \n",
    "\n",
    "Supongamos que se tiene una ventana deslizante de tamaño fijo que se desplaza a lo largo de una frase: la palabra del centro es el **objetivo** y las que están a su izquierda y derecha dentro de la ventana deslizante son las palabras de **contexto**. \n",
    "\n",
    "Consideremos el siguiente ejemplo donde usamos una ventana de tamaño 5 para ir construyendo nuestras muestras de entrenamiento con pares de palabras (objetivo, contexto):\n",
    "\n",
    "<img src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/BBVA/Embeddings/word2vec1.png\" width=\"80%\"> \n",
    "\n",
    "A partir de este conjunto de datos, el modelo Skip-Gram se entrena para predecir las probabilidades de que una palabra sea el contexto de un determinado objetivo. Para ello utiliza una DNN con la siguiente arquitectura:\n",
    "\n",
    "\n",
    "<img src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/BBVA/Embeddings/word2vec3.png\" width=\"80%\"> \n",
    "\n",
    "Las palabras objetivo ($x_1$, ..., $x_v$) están a la entrada de la red con una codificación one-hot. Las palabras contexto ($y_1$, ..., $y_v$) son el objetivo y están a la salida también con una codificación one-hot. De este modo la red, para cada par (objetivo, contexto) debe predecir el contexto de la palabra objetivo. Para ello, la red tiene una capa intermedia que permite modelar el contexto a partir del objetivo. El tamaño de esta capa ($N$) define el tamaño o dimensión de nuestro embedding; para procesado de texto suelen usarse embedding de tamaño 100, 200,... aunque lógicamente esto depende de la complejidad de la base de datos.\n",
    "\n",
    "Usando así el conjunto de entrenamiento que generamos con el corpus de datos, se entrenará la red y se aprenderán los parámetros de red dados por las matrices de entrada $W$ y la de salida $W'$. Mientras que la matriz de salida codifica el contexto, la matriz de entrada (denominada *embedding*) nos da una representación en un espacio de tamaño $N$ de cada una de las palabras objetivo en nuestro corpus. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1PF0aIbv8Ei"
   },
   "source": [
    "## Implementación de word2vec en Gensim\n",
    "\n",
    "Para diseñar un word2vec podemos usar la implementación de  [word2vec](https://radimrehurek.com/gensim/models/word2vec.html) que incluye la librería de gensim. Su uso es bastante sencillo ya que sólo necesita que le facilitemos una colección de frases (él se encarga de generar por nosotros los pares de palabras (objetivo, contexto)) y solo hay que indicarle algunos parámetros:\n",
    "* `size` (tamaño del embedding): el número de dimensiones que tendrá su representación vectorial. Por defecto es 100.\n",
    "* `window` (tamaño de la ventana): el número de palabras adyacentes que se consideran en el mismo contexto de una palabra objetivo. Por defecto es 5.\n",
    "* `sg` (algoritmo word2vec). Debemos indicat `sg=1` si queremos usar el skip-gram.\n",
    "* `min_count`: mínimo número de veces que debe aparecer una palabra en el corpus para ser considerada en el modelo. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "087gNibGPr7v"
   },
   "source": [
    "**Carga de datos** \n",
    "\n",
    "Para empezar a trabajar con este modelo vamos a empezar utilizando uno de los datasets de NLTK. En este caso elegimos el dataset *brown* que contiene 500 fuentes de texto clasificadas por género (noticias, ficción, misterio, comedia, ...). Además, para poder trabajar con este corpus, vamos a dividirlo por frases, para luego analizar las palabras de cada frase y su contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LQ4yHkJdQUyv"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "nltk.download('brown')\n",
    "corpus_sent = brown.sents(categories=['news']) # To fast the word2vec training let's only use news category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8mwapuByYYd"
   },
   "source": [
    "Aqui vamos a usar un dataset tal y como está, pero podríamos lógicamente aplicar todo el preprocesado que hemos visto con NLTK para mejorar el resultado del *embedding* que calculemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5O55hotUlVp"
   },
   "source": [
    "**Definición y entrenamiento del modelo**\n",
    "\n",
    "Ahora vamos a usar la clase [`word2Vec`](https://radimrehurek.com/gensim/models/word2vec.html) de gensim para generar y entrenar el modelo, es decir, para aprender el *embedding* de cada uno de los términos de nuestro corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XX13wyy0QdrX"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(corpus_sent, sg=1, size = 50, window=5, min_count=20)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hx-SfVElYPyx"
   },
   "source": [
    "Una vez tenemos el modelo word2vec, podemos ver el vocabulario del mismo (las palabras consideradas como objetivo para las que tendremos un *embedding*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHAqu1FSRByE"
   },
   "outputs": [],
   "source": [
    "words = list(model.wv.vocab)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xu_YRXmJYX6m"
   },
   "source": [
    "Así como cada uno de los *embeddings* para cada una de estas palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_EbkJWpzSf6N"
   },
   "outputs": [],
   "source": [
    "model.wv['Friday']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yghzaFYaH3NE"
   },
   "source": [
    "## Visualización de Word2Vec: t-SNE\n",
    "\n",
    "Para visualizar el word2vec anterior necesitamos convertir cada *embedding* (tiene dimensión 50) a un espacio bidimensional. Un opción para reducir su dimensión es aplicar un PCA. Sin embargo, para la representación de los word2vec suele usarse el algoritmo [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) (*t-distributed Stochastic Neighbor Embedding*) ya que es capaz de mantener la estructura semántica o local de los datos. \n",
    "\n",
    "Para ello, el t-SNE aplica una reducción de dimensionalidad no lineal para modelar cada *embedding* de alta dimensión mediante un punto bidimensional o tridimensional, de manera que los objetos similares se modelen mediante puntos cercanos y los objetos disímiles se modelen mediante puntos distantes. \n",
    "\n",
    "Sklearn incluye una implementación del [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) que podemos usar fácilmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zu1UcfxsX8TO"
   },
   "outputs": [],
   "source": [
    "# Create numpy array with all word2vec\n",
    "embeddings = model.wv.vectors \n",
    "#embeddings = np.array([model.wv[w] for w in list(model.wv.vocab)])\n",
    "embeddings[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4Tixa2VH3NF"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE()\n",
    "embed_tsne = tsne.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXP3M3bUZg1f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 16))\n",
    "for idx, word in enumerate((model.wv.vocab)):\n",
    "    plt.scatter(*embed_tsne[idx, :], color='steelblue')\n",
    "    plt.annotate(word, (embed_tsne[idx, 0], embed_tsne[idx, 1]), alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrdMe87RH3M1"
   },
   "source": [
    "## Usando modelos preentrenados\n",
    "\n",
    "Gensim incluye funciones para explotar un conjunto de *embeddings* preentrenados. Pueden ser un conjunto de *embeddings* que hemos entrenado nosotros, o puede utilizar directamente un modelo preentrenado con un gran corpus de datos. Muchos de ellos están disponibles en abierto para su uso.\n",
    "\n",
    "Un modelo preentrenado muy popular es el modelo del conjunto de datos de Google News, que contiene *embeddings* de dimensión 300 para un vocabulario de 3 millones de palabras. La siguiente celda de código carga este modelo (tarda un poco...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Xrcr6edfdfI"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t06lwjptgxvI"
   },
   "source": [
    "Una vez cargado el modelo, el acceso a los embeddings es muy sencillo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4YWe8X2H3M-"
   },
   "outputs": [],
   "source": [
    "# Access vectors for specific words with a keyed lookup:\n",
    "vector = wv['sports']\n",
    "# see the shape of the vector (300,)\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wH62tDqNg7gQ"
   },
   "outputs": [],
   "source": [
    "# Processing a sentence\n",
    "vectors = [wv[x] for x in \"This is some text I am processing with Spacy\".split(' ')]\n",
    "\n",
    "len(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jB7CNPWrH3NB"
   },
   "source": [
    "Gensim incluye funciones para explorar los vectores de *embedding* cargados que nos permiten examinar la similitud de las palabras y encontrar sinónimos de palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nj4l4oCH3NC"
   },
   "outputs": [],
   "source": [
    "wv.similarity('baseball','football')   # similitud -- distancia coseno sobre los embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncROG1qbH3NC"
   },
   "outputs": [],
   "source": [
    "wv.similarity('baseball','stomach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiT2Z9UVH3ND"
   },
   "outputs": [],
   "source": [
    "wv.most_similar('neck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gg0VieegdJo"
   },
   "source": [
    "También podemos visualizar (algunas palabras) este *embedding* usando el t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0y7eozBYF3g"
   },
   "outputs": [],
   "source": [
    "# Let's plot only 500 words of the vocab\n",
    "vocab = list(wv.vocab)\n",
    "embeddings_red = [wv[w] for w in vocab[:500]]\n",
    "\n",
    "tsne = TSNE()\n",
    "embed_tsne = tsne.fit_transform(embeddings_red)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 16))\n",
    "for idx, w in enumerate(vocab[:500]):\n",
    "    plt.scatter(*embed_tsne[idx, :], color='steelblue')\n",
    "    plt.annotate(w, (embed_tsne[idx, 0], embed_tsne[idx, 1]), alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxB_1j6RH3NG"
   },
   "source": [
    "## Operaciones semánticas con *embeddings* \n",
    "Para analizar cómo el word2vec es capaz de mantener las relaciones semánticas entre palabras, vamos a hacer un experimento curioso. Vamos a obtener los *embeddings* de las siguientes palabras ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VqY60P_H3NG"
   },
   "outputs": [],
   "source": [
    "king = wv['king']\n",
    "queen = wv['queen']\n",
    "man = wv['man']\n",
    "woman = wv['woman']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tdna3EHH3NH"
   },
   "source": [
    "Si buscamos los vecinos más cercanos (utilizando la distancia del coseno) a la palabra 'king' obtenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XvgAskDH3NH"
   },
   "outputs": [],
   "source": [
    "wv.similar_by_vector(king, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Cp655pNH3NI"
   },
   "source": [
    "Si ahora calculamos el vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ko1YeDuH3NI"
   },
   "outputs": [],
   "source": [
    "v = king - man + woman  # NO ES UNA PALABRA, ES UN VECTOR INTERMEDIO EN EL ESPACIO DE LOS EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKFd-Q1WH3NJ"
   },
   "source": [
    "¿Qué esperas de la palabra resultante? Busquemos las palabras más parecidas con el vector resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYXzgxlgH3NJ"
   },
   "outputs": [],
   "source": [
    "wv.similar_by_vector(v, topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXce0ExwH3NK"
   },
   "source": [
    "Curiosamente, **la similitud con el vector `queen` ha aumentado** Es decir, hemos realizado una operación semántica (`king - man + woman -> queen`) mediante operaciones euclidianas en el espacio de los *embeddings*.\n",
    "\n",
    "De hecho, la operación puede generalizarse simplemente a\n",
    "\n",
    " v = `king` + $\\alpha$ ( - `man` + `woman`) \n",
    " \n",
    "donde utilizando $\\alpha>1$. En el siguiente código calculamos la correlación entre v y `queen` para diferentes valores de $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJaNL3j5H3NK"
   },
   "outputs": [],
   "source": [
    "def cos_dist(v1,v2):\n",
    "    return (v1@v2)/np.linalg.norm(v1)/np.linalg.norm(v2)\n",
    "\n",
    "alpha = np.arange(0,6,0.25)\n",
    "vectors = [king+a*(woman-man) for a in alpha]\n",
    "\n",
    "corr_queen = np.array([cos_dist(v,queen) for v in vectors])\n",
    "corr_king = np.array([cos_dist(v,king) for v in vectors])\n",
    "most_corr_word = [wv.similar_by_vector(v, topn=1, restrict_vocab=None)[0][0] for v in vectors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naUU7zHUH3NK"
   },
   "source": [
    "En el siguiente gráfico mostramos la similitud entre el vector resultante con `king` y `queen`, resaltando con puntos negros los casos en los que `queen` es la palabra más parecida a `king`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5koNeeEH3NL"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plt.plot(alpha,corr_queen,label='Similarity with queen')\n",
    "plt.plot(alpha,corr_king,label='Similarity with king')\n",
    "idx_queen = [w == 'queen' for w in most_corr_word]\n",
    "plt.plot(alpha[idx_queen],corr_queen[idx_queen],'ko',ms='15',label='Queen is the most similar word')\n",
    "plt.legend()\n",
    "plt.xlabel('$alpha$')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuDItKD_H3NL"
   },
   "source": [
    "Así que, efectivamente, con operaciones lineales sobre el espacio de *embeddings* podemos resolver algunas operaciones semánticas sencillas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTDm4NB4IyVO"
   },
   "source": [
    "# *Embeddings* para filtrado colaborativo: Prod2Vec\n",
    "\n",
    "El filtrado colaborativo consiste en hacer predicciones sobre los intereses de un usuario basándose en los intereses de muchos otros usuarios. Así, por ejemplo, en un sistema de recomendación de películas, supongamos que tenemos 1.000.000 de usuarios y una lista de las películas que ha visto cada uno (de un catálogo de 500.000 películas). Nuestro objetivo es recomendar películas a los usuarios.\n",
    "\n",
    "Para resolver este problema se necesita algún método para determinar qué películas son similares entre sí. Podemos lograr este objetivo obteniendo un *embedding* las películas en un espacio de baja dimensión creado de forma que las películas similares estén cerca. Para ello podemos usar las mismas ideas y herramientas del word2vec para obtener embeddings de palabras, por ese motivo esta aproximación se llama Prod2Vec...\n",
    "\n",
    "Veamos como obtener este Prod2Vec para un sistema de recomendación de productos de la compra$^{(*)}$. Para ello, empecemos cargando el siguiente dataset.\n",
    "\n",
    "$^{(*)}$ Este dataset es una versión simplificada del challenge \"*Instacart market basket analysis*\" de [Kaggle](https://www.kaggle.com/c/instacart-market-basket-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ooz6ZO4gnBhx"
   },
   "outputs": [],
   "source": [
    "product_df = pd.read_csv(\"http://www.tsc.uc3m.es/~vanessa/data_notebooks/market_basket/products.csv\")\n",
    "order_product_df = pd.read_csv(\"http://www.tsc.uc3m.es/~vanessa/data_notebooks/market_basket/market_basket_red_v2.zip\").set_index('Unnamed: 0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2dyJuWlaGhH"
   },
   "source": [
    "En este dataset tenemos dos tablas de datos, por un lado la que nos indica los productos disponibles (indica lo que es cada `product_id`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YPQKNMIgrJh"
   },
   "outputs": [],
   "source": [
    "product_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bx4FZ9jiaTqx"
   },
   "source": [
    "Y por otro lado, la tabla con pedidos, para cada compra nos indica los productos que se han comprado y, además, van ordenados. Es decir, nos indica la secuencia de compra de productos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVTaZL7rgt7l"
   },
   "outputs": [],
   "source": [
    "order_product_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rY7Jz7M3qECa"
   },
   "source": [
    "### Construcción del Prod2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BU4tvxgMhn5g"
   },
   "source": [
    "Podemos explotar la estructura secuencial que nos da la tabla `order_product_df` para ver qué productos suelen acompañarse de otros, es decir, para definir el contexto de cada producto. Para ello, solo tenemos que crear estructuras tipo frases con el orden en que se compran los productos dentro del mismo pedido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98dd7e88c8bef2cf4e8e7d014d7b7a4ec8d8101a",
    "id": "_vqqZD9Qmmkf"
   },
   "outputs": [],
   "source": [
    "order_product_list = order_product_df[['order_id','product_id']].values.tolist()\n",
    "\n",
    "product_corpus = []\n",
    "sentence = []\n",
    "new_order_id = order_product_list[0][0]\n",
    "for (order_id, product_id) in order_product_list:\n",
    "    if new_order_id != order_id:\n",
    "        product_corpus.append(sentence)\n",
    "        sentence = []\n",
    "        new_order_id = order_id\n",
    "    sentence.append(str(product_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kL03_nZBkbjX"
   },
   "source": [
    "Analicemos el contenido de estas listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a80edf1212baa8b9471bff6c3fca9d69391965d9",
    "id": "P-1O0FG_mmkh"
   },
   "outputs": [],
   "source": [
    "# Function to help to analyze products\n",
    "def toProductName(id):\n",
    "    id = int(id)\n",
    "    return product_df[product_df.product_id==id]['product_name'].values.tolist()[0]\n",
    "toProductName(24852)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ajho94hyi96N"
   },
   "outputs": [],
   "source": [
    "# Primera frase o primera lista de la compra\n",
    "id_list = 0\n",
    "list_products = [toProductName(id_prod) for id_prod in product_corpus[id_list]]\n",
    "print(list_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-IWA32vkPiU"
   },
   "outputs": [],
   "source": [
    "# Segunda frase o segunda lista de la compra\n",
    "id_list = 1\n",
    "list_products = [toProductName(id_prod) for id_prod in product_corpus[id_list]]\n",
    "print(list_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQAwczTBkhDq"
   },
   "source": [
    "Ahora que tenemos nuestro \"corpus\" de productos o listas de la compra, podemos usar la función `word2vec` de gensim para construir un `prod2vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb98b4f48e72ecbeb8ad2e57ee00cdfcbe161a71",
    "id": "_i3y3iORmmkg"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(product_corpus, window=6, size=100, min_count=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "709653282ad07e272acf0dfb77f525f68ae41e17",
    "id": "C2lUUOs-mmki"
   },
   "source": [
    "### ¿Cuáles son los productos más parecidos?\n",
    "\n",
    "Podemos usar la representación prod2vec o los *embeddings* de los productos para encontrar productos similares:\n",
    "\n",
    "* El producto más parecido a `banana` (24852) es .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f7c26efb1d30c937927bcfe38e1d30bbc631b3d",
    "id": "bD7fs0vGmmki"
   },
   "outputs": [],
   "source": [
    "def most_similar_readable(model, product_id):\n",
    "    similar_list = [(product_id,1.0)]+model.wv.most_similar(str(product_id))\n",
    "    \n",
    "    return [( toProductName(int(id)), similarity ) for (id,similarity) in similar_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0dcbf0cd7cd994f0f134ae80710731bd74f0b49c",
    "id": "DEa8jzL4mmki"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(most_similar_readable(model, 24852), columns=['product','similarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a31f6d9ee8bb5a663487f216603b24f64cc2e87",
    "id": "DlOaFiNvmmkk"
   },
   "source": [
    "* El producto más parecido a `Organic Whole Milk` (27845) es .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51565ce4f70bcec5cd9e1bec1ec2fd6c8f139287",
    "id": "PPylPS2zmmkk"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(most_similar_readable(model, 27845), columns=['product','similarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d51ff51e54e347192814ed41b2e8cf6c08ed60a7",
    "id": "fXdMB8h5mmkk"
   },
   "source": [
    "### Aplicaciones del prod2vec: agrupamiento de productos\n",
    "\n",
    "Podemos usar la representación prod2vec para hacer agrupamiento de productos usándola como entrada de un K-means. Para ello vamos a entrenar un k-means con 500 grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KewQQ2MHc7eX"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "K=500\n",
    "\n",
    "# Get product embeddings\n",
    "prod_emb = model.wv.vectors\n",
    "\n",
    "# Train Kmeans\n",
    "kmeans = KMeans(n_clusters=K) # Definimos objeto con parámetros por defecto\n",
    "kmeans.fit(prod_emb) # Entrenamos k-means\n",
    "y_kmeans = kmeans.predict(prod_emb) # Obtenemos el identificador del grupo para cada dato\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhA7RZ8teEUj"
   },
   "source": [
    "Analicemos los clusters resultantes, para ello podemos ver los productos más parecidos a cada centroide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TuntUVz-mk8g"
   },
   "outputs": [],
   "source": [
    "def most_similar_to_centroid(model, center_emb):\n",
    "    similar_list = model.wv.similar_by_vector(center_emb)\n",
    "    \n",
    "    return [( toProductName(int(id)), similarity ) for (id,similarity) in similar_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5AGJxLWmQkV"
   },
   "outputs": [],
   "source": [
    "center_id = 0\n",
    "pd.DataFrame(most_similar_to_centroid(model, centers[center_id]), columns=['product','similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jTDl22Rf0SD"
   },
   "outputs": [],
   "source": [
    "center_id = 100\n",
    "pd.DataFrame(most_similar_to_centroid(model, centers[center_id]), columns=['product','similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahDacsz2nfHx"
   },
   "outputs": [],
   "source": [
    "center_id = 200\n",
    "pd.DataFrame(most_similar_to_centroid(model, centers[center_id]), columns=['product','similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55h2OfsBcnkk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Embeddings.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
